#!/usr/bin/env python3
"""
ADDITIONAL_CHATBOT_ROLEæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ

è¿½åŠ ã®å½¹å‰²ãŒã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ­£ã—ãçµ±åˆã•ã‚Œã€
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ãŒé©åˆ‡ã«æ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import os
import sys
import tempfile

import yaml


def test_additional_role_integration():
    """è¿½åŠ ã®å½¹å‰²ãŒã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ±åˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
    print("\n[ãƒ†ã‚¹ãƒˆ1] è¿½åŠ ã®å½¹å‰²ã®çµ±åˆ")

    # ä¸€æ™‚çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".yaml", delete=False, encoding="utf-8"
    ) as f:
        yaml.dump(
            {
                "llm_system_prompt": "ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                "llm_response_instruction": "å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
                "llm_context_header": "ã€éå»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‘",
                "llm_query_header": "ã€è³ªå•ã€‘",
                "llm_response_header": "ã€å›ç­”ã€‘",
            },
            f,
            allow_unicode=True,
        )
        temp_config_path = f.name

    try:
        import ai_chatbot

        original_path = ai_chatbot.PROMPTS_PATH
        ai_chatbot.PROMPTS_PATH = temp_config_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None

        # è¿½åŠ ã®å½¹å‰²ã‚’è¨­å®š
        os.environ["ADDITIONAL_CHATBOT_ROLE"] = (
            "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚"
        )

        result = ai_chatbot._load_prompts()

        # è¿½åŠ ã®å½¹å‰²ãŒçµ±åˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "ã€è¿½åŠ ã®å½¹å‰²ãƒ»æ€§æ ¼ã€‘" in result["llm_system_prompt"], (
            "è¿½åŠ ã®å½¹å‰²ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        )
        assert "çµŒé¨“è±Šå¯Œãªã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢" in result["llm_system_prompt"], (
            "è¿½åŠ ã®å½¹å‰²ã®å†…å®¹ãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
        )
        assert result["llm_system_prompt"].startswith("ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"), (
            "ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™"
        )

        print("  âœ… è¿½åŠ ã®å½¹å‰²ãŒæ­£ã—ãçµ±åˆã•ã‚Œã¾ã—ãŸ")

        # è¨­å®šã‚’å¾©å…ƒ
        ai_chatbot.PROMPTS_PATH = original_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None
        del os.environ["ADDITIONAL_CHATBOT_ROLE"]

    finally:
        os.unlink(temp_config_path)


def test_prompt_structure():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ãŒæ­£ã—ãæ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
    print("\n[ãƒ†ã‚¹ãƒˆ2] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ã®ç¢ºèª")

    # ä¸€æ™‚çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".yaml", delete=False, encoding="utf-8"
    ) as f:
        yaml.dump(
            {
                "llm_system_prompt": "ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                "llm_response_instruction": "ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š\n1. ç°¡æ½”ã«å›ç­”ã™ã‚‹",
                "llm_context_header": "ã€éå»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‘",
                "llm_query_header": "ã€è³ªå•ã€‘",
                "llm_response_header": "ã€å›ç­”ã€‘",
            },
            f,
            allow_unicode=True,
        )
        temp_config_path = f.name

    try:
        import ai_chatbot

        original_path = ai_chatbot.PROMPTS_PATH
        ai_chatbot.PROMPTS_PATH = temp_config_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None

        # è¿½åŠ ã®å½¹å‰²ã‚’è¨­å®š
        os.environ["ADDITIONAL_CHATBOT_ROLE"] = "ã‚ãªãŸã¯ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚µãƒãƒ¼ãƒˆæ‹…å½“è€…ã§ã™ã€‚"

        prompts = ai_chatbot._load_prompts()

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        similar_messages = ["éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1", "éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸2"]
        query = "ãƒ†ã‚¹ãƒˆè³ªå•"
        context = "\n".join([f"- {msg}" for msg in similar_messages[:5]])

        # æ–°ã—ã„æ§‹é€ ï¼ˆã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã‚’çµ±åˆï¼‰
        system_instructions = f"""{prompts['llm_system_prompt']}

{prompts['llm_response_instruction']}"""

        prompt = f"""{system_instructions}

{prompts['llm_context_header']}
{context}

{prompts['llm_query_header']}
{query}

{prompts['llm_response_header']}"""

        # æ§‹é€ ã‚’æ¤œè¨¼
        lines = prompt.split("\n")

        # ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ¤œè¨¼
        assert "ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚" in system_instructions, (
            "ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        )
        assert "ã€è¿½åŠ ã®å½¹å‰²ãƒ»æ€§æ ¼ã€‘" in system_instructions, (
            "è¿½åŠ ã®å½¹å‰²ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        )
        assert "ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚µãƒãƒ¼ãƒˆæ‹…å½“è€…" in system_instructions, (
            "è¿½åŠ ã®å½¹å‰²ãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
        )
        assert "ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å›ç­”ã—ã¦ãã ã•ã„" in system_instructions, (
            "å¿œç­”æŒ‡ç¤ºãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
        )

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨ä½“ã®æ§‹é€ æ¤œè¨¼
        assert "ã€éå»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‘" in prompt, "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        assert "éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1" in prompt, "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
        assert "ã€è³ªå•ã€‘" in prompt, "è³ªå•ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        assert "ãƒ†ã‚¹ãƒˆè³ªå•" in prompt, "è³ªå•ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
        assert "ã€å›ç­”ã€‘" in prompt, "å›ç­”ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

        # ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ˆã‚Šå‰ã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        system_index = prompt.index("ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
        context_index = prompt.index("ã€éå»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‘")
        assert system_index < context_index, (
            "ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ˆã‚Šå¾Œã«ã‚ã‚Šã¾ã™"
        )

        # è¿½åŠ ã®å½¹å‰²ãŒå¿œç­”æŒ‡ç¤ºã‚ˆã‚Šå‰ã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        role_index = prompt.index("ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚µãƒãƒ¼ãƒˆæ‹…å½“è€…")
        instruction_index = prompt.index("ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å›ç­”ã—ã¦ãã ã•ã„")
        assert role_index < instruction_index, (
            "è¿½åŠ ã®å½¹å‰²ãŒå¿œç­”æŒ‡ç¤ºã‚ˆã‚Šå¾Œã«ã‚ã‚Šã¾ã™"
        )

        print("  âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ãŒæ­£ã—ãæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™")
        print(f"     - ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå½¹å‰²+æŒ‡ç¤ºï¼‰ãŒå…ˆé ­ã«é…ç½®")
        print(f"     - è¿½åŠ ã®å½¹å‰²ãŒå¿œç­”æŒ‡ç¤ºã‚ˆã‚Šå‰ã«é…ç½®")
        print(f"     - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã®å¾Œã«é…ç½®")

        # è¨­å®šã‚’å¾©å…ƒ
        ai_chatbot.PROMPTS_PATH = original_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None
        del os.environ["ADDITIONAL_CHATBOT_ROLE"]

    finally:
        os.unlink(temp_config_path)


def test_without_additional_role():
    """è¿½åŠ ã®å½¹å‰²ãŒãªã„å ´åˆã®å‹•ä½œç¢ºèª"""
    print("\n[ãƒ†ã‚¹ãƒˆ3] è¿½åŠ ã®å½¹å‰²ãªã—ã®å‹•ä½œ")

    # ä¸€æ™‚çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".yaml", delete=False, encoding="utf-8"
    ) as f:
        yaml.dump(
            {
                "llm_system_prompt": "ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                "llm_response_instruction": "å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
                "llm_context_header": "ã€éå»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‘",
                "llm_query_header": "ã€è³ªå•ã€‘",
                "llm_response_header": "ã€å›ç­”ã€‘",
            },
            f,
            allow_unicode=True,
        )
        temp_config_path = f.name

    try:
        import ai_chatbot

        original_path = ai_chatbot.PROMPTS_PATH
        ai_chatbot.PROMPTS_PATH = temp_config_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None

        # è¿½åŠ ã®å½¹å‰²ã‚’è¨­å®šã—ãªã„
        if "ADDITIONAL_CHATBOT_ROLE" in os.environ:
            del os.environ["ADDITIONAL_CHATBOT_ROLE"]

        result = ai_chatbot._load_prompts()

        # è¿½åŠ ã®å½¹å‰²ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        assert "ã€è¿½åŠ ã®å½¹å‰²ãƒ»æ€§æ ¼ã€‘" not in result["llm_system_prompt"], (
            "è¿½åŠ ã®å½¹å‰²ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã®ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™"
        )
        assert result["llm_system_prompt"].strip() == "ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚", (
            "ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™"
        )

        print("  âœ… è¿½åŠ ã®å½¹å‰²ãªã—ã§ã‚‚æ­£å¸¸ã«å‹•ä½œã—ã¾ã™")

        # è¨­å®šã‚’å¾©å…ƒ
        ai_chatbot.PROMPTS_PATH = original_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None

    finally:
        os.unlink(temp_config_path)


def test_empty_additional_role():
    """ç©ºã®è¿½åŠ ã®å½¹å‰²ã®å‡¦ç†ç¢ºèª"""
    print("\n[ãƒ†ã‚¹ãƒˆ4] ç©ºã®è¿½åŠ ã®å½¹å‰²ã®å‡¦ç†")

    # ä¸€æ™‚çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".yaml", delete=False, encoding="utf-8"
    ) as f:
        yaml.dump(
            {
                "llm_system_prompt": "ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                "llm_response_instruction": "å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
            },
            f,
            allow_unicode=True,
        )
        temp_config_path = f.name

    try:
        import ai_chatbot

        original_path = ai_chatbot.PROMPTS_PATH
        ai_chatbot.PROMPTS_PATH = temp_config_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None

        # ç©ºã®è¿½åŠ ã®å½¹å‰²ã‚’è¨­å®š
        os.environ["ADDITIONAL_CHATBOT_ROLE"] = "   "

        result = ai_chatbot._load_prompts()

        # ç©ºç™½ã®ã¿ã®å ´åˆã¯çµ±åˆã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª
        assert "ã€è¿½åŠ ã®å½¹å‰²ãƒ»æ€§æ ¼ã€‘" not in result["llm_system_prompt"], (
            "ç©ºç™½ã®ã¿ã®è¿½åŠ ã®å½¹å‰²ãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã™"
        )

        print("  âœ… ç©ºç™½ã®ã¿ã®è¿½åŠ ã®å½¹å‰²ã¯ç„¡è¦–ã•ã‚Œã¾ã™")

        # è¨­å®šã‚’å¾©å…ƒ
        ai_chatbot.PROMPTS_PATH = original_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None
        del os.environ["ADDITIONAL_CHATBOT_ROLE"]

    finally:
        os.unlink(temp_config_path)


def test_cache_invalidation():
    """ç’°å¢ƒå¤‰æ•°å¤‰æ›´æ™‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ç¢ºèª"""
    print("\n[ãƒ†ã‚¹ãƒˆ5] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã®å‹•ä½œ")

    # ä¸€æ™‚çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".yaml", delete=False, encoding="utf-8"
    ) as f:
        yaml.dump(
            {
                "llm_system_prompt": "ã‚ãªãŸã¯å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                "llm_response_instruction": "å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
            },
            f,
            allow_unicode=True,
        )
        temp_config_path = f.name

    try:
        import ai_chatbot

        original_path = ai_chatbot.PROMPTS_PATH
        ai_chatbot.PROMPTS_PATH = temp_config_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None

        # æœ€åˆã®è¿½åŠ ã®å½¹å‰²ã‚’è¨­å®š
        os.environ["ADDITIONAL_CHATBOT_ROLE"] = "å½¹å‰²A"
        result1 = ai_chatbot._load_prompts()
        assert "å½¹å‰²A" in result1["llm_system_prompt"], "å½¹å‰²AãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"

        # è¿½åŠ ã®å½¹å‰²ã‚’å¤‰æ›´
        os.environ["ADDITIONAL_CHATBOT_ROLE"] = "å½¹å‰²B"
        result2 = ai_chatbot._load_prompts()
        assert "å½¹å‰²B" in result2["llm_system_prompt"], "å½¹å‰²BãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
        assert "å½¹å‰²A" not in result2["llm_system_prompt"], "å¤ã„å½¹å‰²AãŒæ®‹ã£ã¦ã„ã¾ã™"

        print("  âœ… ç’°å¢ƒå¤‰æ•°å¤‰æ›´æ™‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ­£ã—ãç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™")

        # è¨­å®šã‚’å¾©å…ƒ
        ai_chatbot.PROMPTS_PATH = original_path
        ai_chatbot._prompts = None
        ai_chatbot._cached_additional_role = None
        del os.environ["ADDITIONAL_CHATBOT_ROLE"]

    finally:
        os.unlink(temp_config_path)


def main():
    """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("=" * 60)
    print("ADDITIONAL_CHATBOT_ROLEæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    tests = [
        test_additional_role_integration,
        test_prompt_structure,
        test_without_additional_role,
        test_empty_additional_role,
        test_cache_invalidation,
    ]

    passed = 0
    failed = 0

    for test in tests:
        try:
            test()
            passed += 1
        except AssertionError as e:
            print(f"  âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            failed += 1
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            import traceback

            traceback.print_exc()
            failed += 1

    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆçµæœ")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {passed}")
    print(f"âŒ å¤±æ•—: {failed}")
    print(f"åˆè¨ˆ: {passed + failed}")

    if failed == 0:
        print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        return True
    else:
        print(f"\nâš ï¸  {failed}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
